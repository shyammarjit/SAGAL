{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing python Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 643,
     "status": "ok",
     "timestamp": 1640772728417,
     "user": {
      "displayName": "SHYAM MARJIT",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64",
      "userId": "10874093040693940713"
     },
     "user_tz": -330
    },
    "id": "CYrTggoIbl42"
   },
   "outputs": [],
   "source": [
    "import mne, os, time, pickle, warnings, itertools, copy, sys, shutil\n",
    "from mne.filter import filter_data as bandpass_filter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from sklearn import svm\n",
    "from scipy.signal import welch, butter, lfilter, sosfilt, sosfreqz, freqz\n",
    "from scipy.integrate import simps\n",
    "from scipy.stats import f_oneway\n",
    "from tqdm import tqdm\n",
    "from mne.preprocessing import ICA\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from skfeature.utility.construct_W import construct_W\n",
    "from scipy.sparse import diags\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_names = ['Fp1', 'AF3', 'F3', 'F7', 'FC5', 'FC1', 'C3', 'T7', 'CP5', 'CP1', 'P3', 'P7', 'PO3',\n",
    "            'O1', 'Oz', 'Pz', 'Fp2', 'AF4', 'Fz', 'F4', 'F8', 'FC6', 'FC2', 'Cz', 'C4', 'T8',\n",
    "            'CP6', 'CP2', 'P4', 'P8', 'PO4', 'O2']\n",
    "subject_names = ['s01', 's02', 's03', 's04', 's05', 's06', 's07', 's08', 's09', 's10', 's11', 's12', \n",
    "                 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21',\n",
    "                 's22', 's23', 's24', 's25', 's26', 's27', 's28', 's29', 's30', 's31', 's32']\n",
    "\n",
    "theta_band_range = (4, 8)   # drownsiness, emotional connection, intuition, creativity\n",
    "alpha_band_range = (8, 12)  # reflection, relaxation\n",
    "beta_band_range = (12, 30)  # concentration, problem solving, memory\n",
    "gamma_band_range = (30, 48) # cognition, perception, learning, multi-tasking\n",
    "\n",
    "sf = 128 # sampling frequency 128 Hz\n",
    "\n",
    "\n",
    "eeg_channels = np.array(ch_names)\n",
    "class_labels = ['valence', 'arousal', 'all']\n",
    "\n",
    "my_common_path = '/Users/shyammarjit/Desktop/Brain Computer Interface/'\n",
    "# deap dataset path # put the path in which deap dataset files are present\n",
    "deap_dataset_path = my_common_path + 'Deap Dataset/'\n",
    "# put the path location of datfiles folder s.t. subject wise folder should contain datafiles\n",
    "datafiles_path = my_common_path + 'SAGA+Active Learning/band_48_fir_None_one/'\n",
    "# put the path in which you want to save the csv file\n",
    "save_csv_path = my_common_path + 'SAGA+Active Learning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1640772729210,
     "user": {
      "displayName": "SHYAM MARJIT",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64",
      "userId": "10874093040693940713"
     },
     "user_tz": -330
    },
    "id": "udO6VWBziiQW"
   },
   "outputs": [],
   "source": [
    "def SignalPreProcess(eeg_rawdata):\n",
    "    '''\n",
    "    eeg_rawdata: numpy array with the shape of (n_channels, n_samples)\n",
    "    return: filtered EEG raw data of shape (n_channels, n_samples)\n",
    "    '''\n",
    "    assert eeg_rawdata.shape[0] == 32\n",
    "    eeg_rawdata = np.array(eeg_rawdata)\n",
    "  \n",
    "    info = mne.create_info(ch_names = ch_names, ch_types = ['eeg' for _ in range(32)], sfreq = 128, verbose=False)\n",
    "    raw_data = mne.io.RawArray(eeg_rawdata, info, verbose = False) # create MNE raw file\n",
    "    # Bandpass filter of 4 Hz to 48 Hz\n",
    "    raw_data.load_data(verbose = False).filter(l_freq = 4, h_freq = 48, method = 'fir', verbose = False)\n",
    "    # raw_data.plot()\n",
    "    \n",
    "    # FAST-ICA with 31 number of components\n",
    "    ica = ICA(n_components = N_C, random_state = 97, verbose = False)\n",
    "    ica.fit(raw_data) # fit the data into ica\n",
    "    # https://mne.tools/stable/generated/mne.preprocessing.find_eog_events.html?highlight=find_eog_#mne.preprocessing.find_eog_events\n",
    "    # Take Fp1 channel as the reference channel and find the ICA score to choose artfacts score. \n",
    "    eog_indices, eog_scores = ica.find_bads_eog(raw_data.copy(), ch_name = 'Fp1', verbose = None)\n",
    "    # ica.plot_scores(eog_scores)\n",
    "    a = abs(eog_scores).tolist()\n",
    "    if(droping_components == 'one'): # find one maximum score\n",
    "        ica.exclude = [a.index(max(a))] # exclude the maximum index\n",
    "            \n",
    "    else: # find two maximum scores\n",
    "        a_2 = a.copy()\n",
    "        a.sort(reverse = True)\n",
    "        exclude_index = []\n",
    "        for i in range(0, 2):\n",
    "            for j in range(0, len(a_2)):\n",
    "                if(a[i]==a_2[j]):\n",
    "                    exclude_index.append(j)\n",
    "        ica.exclude = exclude_index # exclude these two maximum indeces\n",
    "    ica.apply(raw_data, verbose = False) # apply the ICA \n",
    "    # common average reference\n",
    "    raw_data.set_eeg_reference('average', ch_type = 'eeg')#, projection = True)\n",
    "    filted_eeg_rawdata = np.array(raw_data.get_data()) # fetch the data from MNE.\n",
    "    return filted_eeg_rawdata\n",
    "\n",
    "def signal_pro(input_data):\n",
    "    for i in range(input_data.shape[0]): # for each video sample call SignalPreProcess\n",
    "        input_data[i] = SignalPreProcess(input_data[i].copy())\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 635,
     "status": "ok",
     "timestamp": 1640772733019,
     "user": {
      "displayName": "SHYAM MARJIT",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64",
      "userId": "10874093040693940713"
     },
     "user_tz": -330
    },
    "id": "z1ZQs2q3Hnno"
   },
   "outputs": [],
   "source": [
    "def bandpower(input_data, band):\n",
    "    band = np.asarray(band)\n",
    "    low, high = band # band is the tuple of (low, high)\n",
    "    nperseg = (2 / low) * sf\n",
    "    # Compute the modified periodogram (Welch)\n",
    "    freqs, psd = welch(input_data, sf, nperseg = nperseg)\n",
    "    # Find closest indices of band in frequency vector\n",
    "    idx_band = np.logical_and(freqs >= low, freqs <= high)\n",
    "    return np.mean(psd[idx_band]) # mean of the frequency bands\n",
    "\n",
    "def bandpower_de(channel_index, input_data, band):\n",
    "    # get Frequency wise data\n",
    "    #print(input_data.shape)\n",
    "    info = mne.create_info(ch_names = ch_names, ch_types = ['eeg' for _ in range(32)], sfreq = 128, verbose = False)\n",
    "    raw_data = mne.io.RawArray(input_data, info, verbose = False)\n",
    "    raw_data.load_data(verbose = False).filter(l_freq = band[0], h_freq = band[1], method = 'fir', verbose = False)\n",
    "    filted_eeg_rawdata = np.array(raw_data.get_data()) #get the filtered data\n",
    "    \n",
    "    #data_band = butter_bandpass_filter(input_data, lowcut=band[0], highcut=band[1], fs = sf, order=1)\n",
    "    \n",
    "    std = np.std(filted_eeg_rawdata[channel_index])#, axis=1, ddof=1)\n",
    "    feature = (-np.log(2*np.pi*np.e*(std)**2))/2\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_label(labels, class_label):\n",
    "    '''\n",
    "    This function gives the valence/arousal and HVHA/HVLA/LAHV/LALV class labels\n",
    "    '''\n",
    "    em_labels = []\n",
    "    if(class_label == 'valence'):\n",
    "        for i in range(0, labels.shape[0]):\n",
    "            if (labels[i][0]>5): # high valence\n",
    "                em_labels.append(1)\n",
    "            else: # low valence\n",
    "                em_labels.append(0)\n",
    "        return em_labels\n",
    "    elif(class_label == 'arousal'):\n",
    "        for i in range(0, labels.shape[0]):\n",
    "            if (labels[i][1]>5): # high arousal\n",
    "                em_labels.append(1)\n",
    "            else: # low arousal\n",
    "                em_labels.append(0)\n",
    "        return em_labels\n",
    "    elif(class_label == 'all'):\n",
    "        for i in range(0, labels.shape[0]):\n",
    "            if (labels[i][0]>5): # high valence\n",
    "                if(labels[i][1]>5): # high arousal\n",
    "                    em_labels.append(1) # HVHA\n",
    "                else:\n",
    "                    em_labels.append(0) # HVLA\n",
    "            else: # low valence\n",
    "                if(labels[i][1]>5): # high arousal\n",
    "                    em_labels.append(2) # LVHA\n",
    "                else: # low arousal\n",
    "                    em_labels.append(3) # LVLA\n",
    "        return em_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 534,
     "status": "ok",
     "timestamp": 1640773030489,
     "user": {
      "displayName": "SHYAM MARJIT",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjgXWgt6yPRlb1Vc2PDp-7CmKEzAlS0XLO2cxEV=s64",
      "userId": "10874093040693940713"
     },
     "user_tz": -330
    },
    "id": "I4DEPV9z4a4q"
   },
   "outputs": [],
   "source": [
    "def get_csv_file(subject, filter_data, labels):\n",
    "    psd_theta, psd_alpha, psd_beta, psd_gamma = [], [], [], []\n",
    "    psd_theta_feat, psd_alpha_feat, psd_beta_feat, psd_gamma_feat = [], [], [], []\n",
    "    de_theta_feat, de_alpha_feat, de_beta_feat, de_gamma_feat = [], [], [], []\n",
    "    de_theta, de_alpha, de_beta, de_gamma = [], [], [], []\n",
    "    for video_no in range (len(filter_data)):\n",
    "        de_input_data = copy.deepcopy(filter_data[video_no])\n",
    "        for channel_no in range (0, len(filter_data[0])):\n",
    "            temp = copy.deepcopy(filter_data[video_no, channel_no])\n",
    "            \n",
    "            # PSD Features\n",
    "            psd_theta.append(bandpower(temp, theta_band_range))\n",
    "            psd_alpha.append(bandpower(temp, alpha_band_range))\n",
    "            psd_beta.append(bandpower(temp, beta_band_range))\n",
    "            psd_gamma.append(bandpower(temp, gamma_band_range))\n",
    "            \n",
    "            # DE features\n",
    "            de_theta.append(bandpower_de(channel_no, de_input_data, theta_band_range))\n",
    "            de_alpha.append(bandpower_de(channel_no, de_input_data, alpha_band_range))\n",
    "            de_beta.append(bandpower_de(channel_no, de_input_data, beta_band_range))\n",
    "            de_gamma.append(bandpower_de(channel_no, de_input_data, gamma_band_range))\n",
    "    # PSD feature matrix\n",
    "    psd_theta = np.reshape(psd_theta, (40, 32)) # 40 videos and 32 channels theta band power\n",
    "    psd_alpha = np.reshape(psd_alpha, (40, 32))\n",
    "    psd_beta = np.reshape(psd_beta, (40, 32))\n",
    "    psd_gamma = np.reshape(psd_gamma, (40, 32))\n",
    "    \n",
    "    # DE based feature matrix\n",
    "    de_theta = np.reshape(de_theta, (40, 32))\n",
    "    de_alpha = np.reshape(de_alpha, (40, 32))\n",
    "    de_beta = np.reshape(de_beta, (40, 32))\n",
    "    de_gamma = np.reshape(de_gamma, (40, 32))\n",
    "    \n",
    "    \n",
    "    for i in range(0, len(eeg_channels)):\n",
    "        psd_theta_feat.append(eeg_channels[i] + '_psd_theta')\n",
    "        psd_alpha_feat.append(eeg_channels[i] + '_psd_alpha')\n",
    "        psd_gamma_feat.append(eeg_channels[i] + '_psd_gamma')\n",
    "        psd_beta_feat.append(eeg_channels[i] + '_psd_beta')\n",
    "        \n",
    "        de_theta_feat.append(eeg_channels[i] + '_de_theta')\n",
    "        de_alpha_feat.append(eeg_channels[i] + '_de_alpha')\n",
    "        de_gamma_feat.append(eeg_channels[i] + '_de_gamma')\n",
    "        de_beta_feat.append(eeg_channels[i] + '_de_beta')\n",
    "        \n",
    "        \n",
    "    df_psd_theta = pd.DataFrame(psd_theta, columns = psd_theta_feat)\n",
    "    df_psd_alpha = pd.DataFrame(psd_alpha, columns = psd_alpha_feat)\n",
    "    df_psd_beta = pd.DataFrame(psd_beta, columns =  psd_beta_feat)\n",
    "    df_psd_gamma = pd.DataFrame(psd_gamma, columns = psd_gamma_feat)\n",
    "    \n",
    "    df_de_theta = pd.DataFrame(de_theta, columns = de_theta_feat)\n",
    "    df_de_alpha = pd.DataFrame(de_alpha, columns = de_alpha_feat)\n",
    "    df_de_beta = pd.DataFrame(de_beta, columns = de_beta_feat)\n",
    "    df_de_gamma = pd.DataFrame(de_gamma, columns = de_gamma_feat)\n",
    "    \n",
    "    # make a directory to save the csv file\n",
    "    new_path = newpath + subject\n",
    "    try:\n",
    "        os.mkdir(new_path)\n",
    "    except:\n",
    "        # If directory exists then delete that directory\n",
    "        shutil.rmtree(new_path)\n",
    "        # then make the new directory\n",
    "        os.mkdir(new_path)\n",
    "    #===========================   ALL Bands   ==================================\n",
    "    frames = [df_psd_theta, df_psd_alpha, df_psd_beta, df_psd_gamma,\\\n",
    "              df_de_theta, df_de_alpha, df_de_beta, df_de_gamma]\n",
    "    all_bands = pd.concat(frames, axis = 1) # join these 8 data frame columns wise, row is fixed\n",
    "    #all_bands.to_csv(new_path + subject + '.csv', index = False, encoding = 'utf-8-sig')\n",
    "    all_bands_valence, all_bands_arousal, all_bands_all = all_bands.copy(), all_bands.copy(), all_bands.copy()\n",
    "    all_bands_valence['valence'] = emotion_label(labels, 'valence')\n",
    "    all_bands_arousal['arousal'] = emotion_label(labels, 'arousal')\n",
    "    all_bands_all['four_class'] = emotion_label(labels, 'all')\n",
    "    all_bands_valence.to_csv(new_path + '/' + subject + '_valence.csv', index = False, encoding = 'utf-8-sig')\n",
    "    all_bands_arousal.to_csv(new_path + '/' + subject + '_arousal.csv', index = False, encoding = 'utf-8-sig')\n",
    "    all_bands_all.to_csv(new_path + '/' + subject + '_four_class.csv', index = False, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  s01\n",
      "Done:  s02\n",
      "Done:  s03\n",
      "Done:  s04\n",
      "Done:  s05\n",
      "Done:  s06\n",
      "Done:  s07\n",
      "Done:  s08\n",
      "Done:  s09\n",
      "Done:  s10\n",
      "Done:  s11\n",
      "Done:  s12\n",
      "Done:  s13\n",
      "Done:  s14\n",
      "Done:  s15\n",
      "Done:  s16\n",
      "Done:  s17\n",
      "Done:  s18\n",
      "Done:  s19\n",
      "Done:  s20\n",
      "Done:  s21\n",
      "Done:  s22\n",
      "Done:  s23\n",
      "Done:  s24\n",
      "Done:  s25\n",
      "Done:  s26\n",
      "Done:  s27\n",
      "Done:  s28\n",
      "Done:  s29\n"
     ]
    }
   ],
   "source": [
    "N_C = None\n",
    "droping_components = 'one'\n",
    "valence_acc, arousal_acc, four_acc = [], [], []\n",
    "for subject in subject_names:\n",
    "    newpath = save_csv_path + '/band_48_fir_None_one/'\n",
    "    try:\n",
    "        # If the directory already exists then don't make any new dirctory\n",
    "        os.mkdir(newpath)\n",
    "    except:\n",
    "        pass\n",
    "    # load the dataset\n",
    "    with open(deap_dataset_path + subject + '.dat', 'rb') as f:\n",
    "        raw_data = pickle.load(f, encoding = 'latin1')\n",
    "    # raw_data has two key 'data' and 'labels'\n",
    "    data = raw_data['data']\n",
    "    labels = raw_data['labels']\n",
    "    # we are excluding 3s pre base line i.e. first 3*128 = 384 data points from time series data\n",
    "    reduced_eeg_data  = data[0:40, 0:32, 384:8064]\n",
    "    filter_data = signal_pro(reduced_eeg_data.copy())\n",
    "    get_csv_file(subject, filter_data, labels)\n",
    "    print('Done: ', subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  s30\n",
      "Done:  s31\n",
      "Done:  s32\n"
     ]
    }
   ],
   "source": [
    "N_C = None\n",
    "droping_components = 'one'\n",
    "valence_acc, arousal_acc, four_acc = [], [], []\n",
    "for subject in subject_names[29:]:\n",
    "    newpath = save_csv_path + '/band_48_fir_None_one/'\n",
    "    try:\n",
    "        # If the directory already exists then don't make any new dirctory\n",
    "        os.mkdir(newpath)\n",
    "    except:\n",
    "        pass\n",
    "    # load the dataset\n",
    "    with open(deap_dataset_path + subject + '.dat', 'rb') as f:\n",
    "        raw_data = pickle.load(f, encoding = 'latin1')\n",
    "    # raw_data has two key 'data' and 'labels'\n",
    "    data = raw_data['data']\n",
    "    labels = raw_data['labels']\n",
    "    # we are excluding 3s pre base line i.e. first 3*128 = 384 data points from time series data\n",
    "    reduced_eeg_data  = data[0:40, 0:32, 384:8064]\n",
    "    filter_data = signal_pro(reduced_eeg_data.copy())\n",
    "    get_csv_file(subject, filter_data, labels)\n",
    "    print('Done: ', subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Step:1-- Subject Independent Channel Selection (CSV File creation) without details",
   "provenance": [
    {
     "file_id": "1CjDHYcPa2wfYjdtlnzd_sU2166e7yk9t",
     "timestamp": 1640771607811
    },
    {
     "file_id": "1Oq_KNSUgTdGEgY3QlUewpCOjzUxlBQQI",
     "timestamp": 1638476734009
    },
    {
     "file_id": "1_aNd9W_ox0bPqI3ULdUB0VDEOOAvN__A",
     "timestamp": 1637694566869
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
